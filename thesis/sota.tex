\documentclass[sigproc-sp.tex]{subfiles} 
\begin{document}
\section{Stato dell'arte}
A partire dal problema che cerchiamo di risolvere, è importante iniziare a calarsi nel concreto, rendendosi conto di quali sono i campi a cui ci si vuole ispirare per costruire un’architettura funzionale alla soluzione della questione.

\subsection{Web semantico}
Con il termine “web semantico”, coniato dal suo ideatore Tim Berners-Lee, si intende “la trasformazione del World Wide Web in un ambiente dove i documenti pubblicati (pagine HTML, file, immagini, e così via) sono associati ad informazioni e dati che ne specificano il contesto semantico in un formato adatto all'interrogazione e l'interpretazione (e.g. tramite motori di ricerca) e, più in generale, all'elaborazione automatica.”\footnote{\url{http://it.wikipedia.org/wiki/Web_semantico}}
Ciò non significa limitare le numerosissime forme in cui è possibile presentare i contenuti sul web, bensì è un modo per fornire una struttura capace di rispondere a delle query, permettendo la lettura automatica di pagine e documenti. 
Risorse con questa caratteristica sono enormemente utili per la facilità con la quale è possibile estrarre informazioni e adattarle alle proprie necessità; sono quindi queste la scelta più ovvia come semplice punto di partenza per la ricerca di contenuti atti a stimolare la reminiscenza.
Una delle realtà più grosse che opera nel web semantico è DBpedia, il cui approccio è quello di effettuare periodicamente il parsing dei dump rilasciati da Wikipedia, estrarre le uniche informazioni strutturate delle pagine (le cosiddette infobox), unendo alcuni attributi delle versioni localizzate dello stesso articolo e rappresentando le risorse tramite Resource Description Framework (RDF). Ogni risorsa è definita tramite un URI, un identificatore unico dell’entità presentata. Il lavoro di DBpedia è eccellente, ma è involontariamente ostacolato dagli editori di Wikipedia, che per la compilazione delle infobox non hanno dei template ben definiti, finendo per rappresentare lo stesso attributo in articoli diversi con nomi diversi; DBpedia è interrogabile tramite SPARQL, un linguaggio SQL-like costruito per leggere RDF. Dopo il rilascio del primo dataset al pubblico nel 2007, la situazione attuale è quella di un grosso grafo composto da molti altri set di dati collegati tra di loro tramite l’accoppiamento di risorse appartenenti a insiemi diversi, ma rappresentanti la stessa entità. Pubblicare questi Linked Data rende molto più facile la ricerca di informazioni sul web, rendendole molto più precise e complete. Altri progetti di web semantico sono: Freebase, che a differenza di DBpedia è un progetto proprietario; Uniprot, una knowledge base contenente dati liberamente accessibili sulle sequenze di proteine; GeoNames, un database geografico contentente oltre 10 milioni di luoghi, accessibile e scaricabile sotto licenza Creative Commons.
\`{E} disponibile online lo stato dei collegamenti tra datasets semantici in forma di grafo, aggiornato a settembre 2011\footnote{\url{http://lod-cloud.net/versions/2011-09-19/lod-cloud.html}}, mentre una descrizione di DBpedia in particolare è reperibile in \cite{bizer2009dbpedia}.

Un approccio diverso nell’attribuzione di un significato ai contenuti presenti sul web è quello dei microformati\footnote{\url{http://microformats.org/}}, un’estensione di markup che, tramite l’utilizzo degli attributi HTML class, rel e rev, consente l’attribuzione di regole semantiche a normali pagine web: figura \ref{fig:microformats} mostra la differenza tra le informazioni sul contatto di Nicola Parrello in maniera canonica e le stesse, se 
riscritte con il microformato hCard (specifico per i contatti).

Attraverso i microformati, ad esempio, un software come un browser può estrarre facilmente informazioni e navigare le relazioni tra oggetti diversi, mantenendo comunque la normale leggibilità di una pagina web. Oltre ad hCard, solo hCalendar è stato formalizzato: altri microformati, come hAtom, hMedia e hNews (rispettivamente per feed Atom, contenuti multimediali e notizie) sono solo più o meno abbozzati, e non rappresentano quindi uno standard.

\subsection{Web search e contestualizzazione dell’informazione} 
Il passo successivo nella ricerca di una soluzione ad problema che è tema di questo documento, dopo aver scelto da dove reperire i dati, è quello di decidere come permettere a un eventuale utente di accedere ai contenuti che vogliamo proporre. L’approccio che sembra più naturale è quello di costruire un piccolo motore di ricerca, in modo tale da creare una maschera che permetta una richiesta di risorse in maniera uniforme, anche se da fonti diverse; inoltre, per avere una ricerca rapida e reattiva, il buon senso suggerisce che è una buona idea quella di indicizzare il materiale ricercabile.
In questo campo è difficile non considerare Google come lo stato dell’arte, essendo loro il search engine più utilizzato al mondo. Perché utenti da ogni parte del globo possano utilizzare un servizio veloce ed efficiente, Google utilizza sette componenti dinamiche che salvano e leggono dati in altre strutture; il procedimento può essere riassunto così:
\begin{enumerate}
  \item Il Server URL parte da un URL di base e, leggendo il Document Index, invia gli URL ai Crawler;
  \item I Crawler scaricano le pagine web e le mandano nello Store Server.
  \item Lo Store Server comprime le pagine nel formato zlib (RFC1950\footnote{\url{http://www.ietf.org/rfc/rfc1950.txt}}), riducendo la loro dimensione a un terzo dell’originale, che vengono poi di un docId univoco e immagazzinate nel repository.;
  \item Il repository viene letto dall’Indexer, che decomprime i documenti e li parsa, assegnando a ogni parola (a cui viene assegnato un wordId univoco) informazioni su posizione, grandezza del testo, numero di occorrenze e altro; ogni voce viene poi aggiunta ad un indice parzialmente ordinato. Dalle pagine lette, l’Indexer estrae anche i dati dei link in esse contenuti, oltre a servirsi del testo analizzato per costruire un lessico, utile per la vera e propria funzione di ricerca;
  \item Lo URL Resolver combina i documenti con i dati dei link, per costruire tabelle di coppie di docId, utilizzati per calcolare il PageRank;
  \item Il Sorter riordina l’indice (ordinato per docId) in un indice inverso (ordinato per wordId), aggiungendo altri dati per rendere la ricerca più precisa;
  \item Infine viene calcolato il PageRank, una misura dell’importanza di una pagina web calcolata in base a quali e quante sono le pagine che hanno dei link che puntano a essa.
\end{enumerate}

Per una trattazione più approfondita, rimandiamo a \cite{brin1998anatomy}.

Negli anni Google è diventato colmo di pubblicità, mostrata e scelta in base ai dati raccolti dalle ricerche degli utenti, ma certamente non è l’unica possibilità in quanto a motori di ricerca. Un esempio su tutti è quello di Duck Duck Go che, a differenza di Google, è un Semantic Search Engine. Il sistema cioè si occupa di valutare l’effettivo significato dei termini di ricerca, eliminando in maniera più precisa i risultati irrilevanti. Ma quello che lo contraddistingue in maniera maggiore dagli altri è la sua attenzione alla privacy: Duck Duck Go infatti non conserva e non vende a terzi nessuna informazione sulle ricerche, permettendo una ricerca anonima e al sicuro da data leak, richieste legali da parte delle istituzioni e disonesti.\footnote{\url{https://duckduckgo.com/privacy}}
Quello che può infastidire gli utenti, cioè gli annunci di cui sopra, sono però molto interessanti per la nostra ricerca, in quanto introducono un altro aspetto molto importante: perché la ricerca sia semplice da utilizzare, e soprattutto piacevole, può essere necessario renderla per così dire automatica, nascondendo l’azione manuale dell’inserimento di parametri e mostrando i risultati direttamente come contesto di qualche altra azione. Premiata nel 2012 dal magazine Popular Science come innovazione dell’anno\footnote{\url{http://www.popsci.com/bown/2012/product/google-now}}, Google Now è un’estensione dell’applicazione mobile Google Search che, oltre ad essere un assistente vocale, analizza abitudini, ricerche e posizioni ricorrenti per fornire dati e risultati contestuali, mostrando all’utente le informazioni prima che egli ne faccia richiesta esplicita all’app.

\subsection{Algoritmi spazio-temporali}
Abbiamo definito la raccolta e la ricerca, ma un ultimo punto rimane fumoso: in base a quale criterio scegliere un set di risorse rispetto a un altro, con la condizione che queste siano effettivamente rilevanti ed efficaci nella stimolazione della reminiscenza? Il vissuto di un individuo può essere riassunto in una lista di eventi, di storie di vita; allo stesso tempo, un evento può essere identificato da una coppia <D,L>, dove D è la coordinata temporale e L descrive la posizione nello spazio. Utilizzando questo modello, il criterio di cui sopra diventa quello della distanza spazio-temporale tra due entità, e il calcolo di questa distanza diventa il mezzo per effettuare un’indicizzazione preliminare delle risorse.

Un interessante esempio di sfruttamento estensivo delle informazione su tempo e spazio al fine di restituire dei risultati a una query è TimeTrails. TimeTrails è un sistema per l’estrazione e l’esplorazione di coordinate spazio-temporali che si possono trovare nei documenti di testo, composto di tre componenti principali: (1) una pipeline che, dopo aver letto i dati forniti da dei moduli che estraggono documenti di testo da varie sorgenti (e.g. la vetrina di Wikipedia\footnote{\url{http://it.wikipedia.org/wiki/Wikipedia:Vetrina}}), si occupa di estrarre le date e i luoghi contenuti nel testo, normalizzarli (e.g. da “25 luglio 1991” a “25/07/1991” per le prime e da “Pergine Valsugana” a “46.06853620, 11.23528960” per i luoghi), e calcolare il numero e la posizione delle occorrenze trovate, in modo da verificare se la coordinata dello spazio e quella del tempo identificano un evento ben preciso oppure se sono due riferimenti senza alcuna correlazione. Il risultato dell’elaborazione, cioè il documento originale unito a una sequenza ordinata di tuple <D,L>, viene poi salvato in (2) un database ottimizzato per contenere dati su luoghi\footnote{\url{http://postgis.net/}}, dal quale (3) un’interfaccia permette la ricerca testuale di documenti, con un risultato che verrà mostrato su una mappa sotto forma di traiettoria, rappresentata da tutte le tuple lette dal db. Nel caso la query dovesse restituire più di un documento, può risultare interessante vedere dove e quando le traiettorie si incrociano: se i documenti sono biografie, l’intersezione delle traiettorie in uno dei punti segnati dalle tuple <D,L> può indicare che i personaggi si sono incontrati.
TimeTrails è presentato dai suoi ideatori in \cite{strotgen2010timetrails}.

\subsection{IT per la reminiscenza}
\label{subsec:related}
Reminiscens non è di certo il primo lavoro compiuto con l’IT al servizio della reminiscenza; discuteremo brevemente alcuni approcci qui di seguito.

Pensieve\footnote{\url{http://pensieve.cornellhci.org/}} è un sistema ideato per inviare a intervalli regolari degli stimoli a ricordare. Tali stimoli possono essere interattivi (come una domanda, e.g. “Ti ricordi quando hai imparato a cucinare?”), oppure semplicemente visuali: in questo ultimo caso, è richiesto un collegamento dell’account Pensieve con importanti e popolari servizi, come Picasa, Flickr e Twitter, dai quali Pensieve provvede a estrarre le immagini e i post che verranno utilizzati come contenuto per inviare i trigger all’utente. Tra i risultati del progetto, è stato notato che le persone preferiscono un tipo di reminiscenza di tipo sociale, ma è conseguibile in maniera migliore tramite un'interazione faccia a faccia; questo e gli altri risultati di Pensieve sono descritti in \cite{cosley2012experiences}.

Simile a questo possiamo trovare anche il social network Proust\footnote{\url{http://www.proust.com/}}, che è basato solo su quesiti riguardanti la vita di un individuo e sulle risposte che lo stesso dà. Le risposte, arricchite con informazioni su luogo e tempo, vengono utilizzate per comporre la storia dell’utente, e visualizzate in forma di libro da mostrare agli altri utenti. Proprio la condivisione di queste storie, unita alla possibilità che determinati utenti hanno di chiedere al diretto interessato qualcosa sul suo passato, costituisce il punto di forza di Proust.

Un progetto molto interessante, che si discosta da quelli appena presentati per il suo non essere un sistema informatico, è Alive Inside\footnote{\url{http://www.ximotionmedia.com/}}, che presenta gli effetti per così dire miracolosi, su alcuni anziani malati di Alzheimer e affetti da demenza senile, della musica da loro ascoltata in gioventù. Il risultato è un documentario d’effetto che mostra come essi vengano “svegliati” dalla musica, che fa riaffiorare in un lampo ricordi del passato e li rende in grado di rispondere a domande, in un modo che fino a pochi istanti prima sembrava impossibile: l’obiettivo del film è infatti sensibilizzare le case di cura e gli ospedali, ma anche le famiglie, all’uso di questa terapia semplice ed economica, quanto efficace.

Numerosi sono stati i tentativi di costruire una banca dati culturale, e un esempio è Memoro\footnote{\url{http://www.memoro.org/}}, piattaforma tutta italiana ma ormai estesa e localizzata in molte regioni del mondo che, prendendo spunto dalla pratica del racconto delle proprie esperienze, tipica di genitori e nonni nei confronti di figli e nipoti, si propone come un contenitore di clip audio e video raccolti dagli utenti, clip che contengono la memoria di vite vissute secondo usanze e valori di un'altra epoca, rendendola disponibile a chiunque abbia 10 minuti di tempo da spendere.

Proseguendo sulla stessa linea, una menzione speciale va a Live Memories\footnote{\url{http://www.livememories.org/}}, progetto locale coordinato da FBK, Università di Trento e Università di Southampton e orientato alla costruzione di un archivio multimediale eterogeneo, raccogliendo dati da sorgenti molto diverse tra loro. Il progetto, che ha avuto luogo dal 2008 al 2011, si è concluso dopo aver coinvolto, oltre agli enti accademici, anche il quotidiano l’Adige, la rivista Vita Trentina e il consiglio comunale di Trento.

Per quanto riguarda i modi in cui è possibile rappresentare entità caratterizzate da coordinate spazio-temporali, i due approcci principali sono (1) tramite punti su una mappa e (2) con l’utilizzo di timeline; mentre il primo è stato utilizzato da TimeTrails, il secondo è quello scelto da Project Greenwich\footnote{\url{http://projectgreenwich.research.microsoft.com/}}, realizzato da Microsoft Research Cambridge. Tramite il login a Facebook, permette di creare delle timeline con le proprie fotografie, arricchirle collegandoci delle pagine da Wikipedia, confrontarle con le timeline create da altri utenti e condividerle con famiglia e amici. Il sistema è stato studiato per permettere agli utenti di riflettere sul loro passato, magari guadagnando consapevolezza, fornendo anche gli strumenti per organizzare i contenuti in maniera creativa ed espressiva.
\end{document}